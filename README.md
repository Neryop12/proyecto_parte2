# Documentaci√≥n T√©cnica en Markdown para el Proyecto R
### Descripci√≥n del C√≥digo
Este documento detalla el c√≥digo R proporcionado en el archivo proyecto fase 2.R, el cual utiliza m√©todos de miner√≠a de datos como √°rboles de decisi√≥n y bosques aleatorios (Random Forest). A continuaci√≥n, se describen las distintas secciones del c√≥digo y las instrucciones necesarias para implementarlo en otro ambiente.

### 1. Cargar Librer√≠as Necesarias
library(readr) 

library(arules)

library(rpart)

library(rpart.plot)

library(randomForest)

library(ggplot2)

### 2. Lectura y Transformaci√≥n de Datos
Leer el archivo CSV

data <- read_csv('..\\edad y causas.csv')

Limpieza de Datos

data <- data %>%
  mutate(Hombres = as.numeric(gsub(",", "", Hombres)),
         Mujeres = as.numeric(gsub(",", "", Mujeres)))

### 3. Filtrado de Datos

data_filtrado <- subset(data, !(Enfermedad %in% c("Todas las causas", "Ignorado")))

### 4. Categorizaci√≥n de Datos
data$Grupo_Hombres <- ifelse(data$Hombres > 50000, "Alta incidencia", "Baja incidencia")

data$Grupo_Mujeres <- ifelse(data$Mujeres > 50000, "Alta incidencia", "Baja incidencia")

### 7. Implementaci√≥n de √Årboles y Random Forest

data_arbol <- read_csv('C:\\Users\\NOrellana\\Documents\\U\\Maestria\\data mining\\proyecto No1\\departamento y causas.csv')

# Limpieza de columnas num√©ricas
data_arbol$`Primera consulta` <- as.numeric(gsub(",", "", data_arbol$`Primera consulta`))

data_arbol$Reconsulta <- as.numeric(gsub(",", "", data_arbol$Reconsulta))

data_arbol$Emergencia <- as.numeric(gsub(",", "", data_arbol$Emergencia))

## Instrucciones para Implementar en Otro Ambiente

1. Instalar R y RStudio:

    a. Descargar R desde [CRAN](https://cran.r-project.org/).
  
    b. Descargar RStudio desde [Rstudio](https://posit.co/).

2. Instalar las Librer√≠as Necesarias:

    Ejecutar el siguiente c√≥digo para instalar todas las librer√≠as:

    install.packages(c("readr", "arules", "rpart", "rpart.plot", "randomForest", "ggplot2"))

3. Actualizar Rutas de los Archivos:

    Reemplazar las rutas de archivos CSV por las rutas locales en tu sistema.

   data <- read_csv("ruta/a/tu/archivo/edad_y_causas.csv")

   data_arbol <- read_csv("ruta/a/tu/archivo/departamento_y_causas.csv")

4. Ejecutar el C√≥digo:

    Cargar el script completo en RStudio y ejecutar secciones del c√≥digo utilizando Ctrl + Enter.

### Notas Adicionales

Par√°metros del Algoritmo Apriori:
Ajusta los valores de support y confidence seg√∫n el tama√±o y caracter√≠sticas de tu conjunto de datos.
Recursos de Hardware:
Procesar grandes conjuntos de datos con Random Forest puede requerir mayor capacidad de memoria RAM.



#üìÑ Documentaci√≥n T√©cnica para el C√≥digo de Redes Neuronales
### üìù Descripci√≥n del C√≥digo
Este script utiliza una red neuronal con TensorFlow y Keras para predecir una variable a partir de un conjunto de datos CSV. Se incluyen pasos de limpieza, preprocesamiento, definici√≥n del modelo, entrenamiento y evaluaci√≥n.

### üìå Bibliotecas Utilizadas
pandas: Para la manipulaci√≥n y limpieza de datos.
numpy: Para operaciones num√©ricas.
scikit-learn: Para dividir el conjunto de datos en entrenamiento y prueba.
TensorFlow y Keras: Para construir y entrenar una red neuronal.
### üöÄ Explicaci√≥n Detallada del C√≥digo

1. Importaci√≥n de Bibliotecas
    ``` python
    
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense
    ```
    Estas bibliotecas se utilizan para manipular datos, dividir el dataset y definir una red neuronal.
2. Carga y Limpieza del Conjunto de Datos
    ```python
    
    data = pd.read_csv("./departamento y causas.csv")
    data.replace(',', '.', regex=True, inplace=True)
    data.replace('-', np.nan, inplace=True)
    ```

    Carga de datos desde un archivo CSV.

    Reemplazo de comas por puntos para estandarizar datos num√©ricos.

    Reemplazo de guiones (-) con valores nulos (NaN).
4. Conversi√≥n de Columnas Num√©ricas
    ```python
    
    numerical_columns = data.columns[2:]  # Ajustar seg√∫n tu archivo
    for col in numerical_columns:
        data[col] = pd.to_numeric(data[col], errors='coerce')
    ```
    Convierte columnas num√©ricas a tipo float.
5. Codificaci√≥n de Variables Categ√≥ricas
    ```python
    categorical_columns = ['Grupos de edad', 'Sexo']
    data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)
    ```
    Codificaci√≥n One-Hot para columnas categ√≥ricas (Grupos de edad y Sexo).
6. Eliminaci√≥n de Filas con Datos Faltantes
    ```python
    
    data.dropna(inplace=True)
    ```
    Elimina filas con valores nulos.
7. Separaci√≥n de Caracter√≠sticas y Objetivo
    ```python
    
    y = data['Primera consulta']
    X = data.drop('Primera consulta', axis=1)
    ```
    X: Caracter√≠sticas (variables predictoras).
    y: Variable objetivo (Primera consulta).
8. Divisi√≥n del Conjunto de Datos
    ```python
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    ```
    Divide los datos en 80% entrenamiento y 20% prueba.
9. Definici√≥n del Modelo de Red Neuronal
    ```python
    
    model = Sequential()
    model.add(Dense(100, input_dim=X_train.shape[1], activation='relu'))
    model.add(Dense(70, activation='relu'))
    model.add(Dense(50, activation='relu'))
    model.add(Dense(10, activation='relu'))
    model.add(Dense(1, activation='linear'))
    ```
    Red neuronal secuencial con capas densas:
    5 capas ocultas con funciones de activaci√≥n ReLU.
    1 capa de salida con activaci√≥n linear para regresi√≥n.
10. Compilaci√≥n del Modelo
    ```python
    
    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])
    ```
    Funci√≥n de p√©rdida: mean_squared_error.
    Optimizador: adam.
    M√©trica: mean_absolute_error.
11. Entrenamiento del Modelo
    ```python
    Copy code
    model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_test, y_test))
    ```
    √âpocas: 50.
    Batch size: 8.
12. Evaluaci√≥n del Modelo
    ```python
    Copy code
    loss, mae = model.evaluate(X_test, y_test)
    print(f"Mean Absolute Error: {mae}")
    ```
    Eval√∫a el modelo y muestra el error absoluto medio.
13. Predicciones
    ```python
    Copy code
    predictions = model.predict(X_test)
    print("Primeras 5 predicciones:")
    print(predictions[:5])
    ```
    Genera predicciones en el conjunto de prueba.
### üõ†Ô∏è Instrucciones para Implementar en Otro Entorno
1. Requisitos Previos

   Instalar las bibliotecas necesarias:

  ```bash
  pip install pandas numpy scikit-learn tensorflow
  ```
2. Estructura de Archivos
   
    Aseg√∫rate de tener un archivo CSV llamado departamento y causas.csv en el mismo directorio que el script.

3. Ejecuci√≥n del C√≥digo

    Guarda el script como red_neuronal.py y ejec√∫talo con:

    ```bash
    python red_neuronal.py
    ```

